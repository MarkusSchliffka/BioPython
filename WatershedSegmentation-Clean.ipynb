{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Watershedding on a TYX shape image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages to open and view tiffile, other python packages to deal with loading images from a certain directory. For writting results we need to create another directory, this is done by pathlib. Local function definations are included in the utils.py file which is imported along with other python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tifffile import imread\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "from utils import NormalizeFloat, save_tiff_imagej_compatible,WatershedImage, WatershedImageMarker\n",
    "from utils import MedianFilter, LocalThreshold3D, LocalThreshold2D, Canny3D, Canny,BackGroundCorrection3D,BackGroundCorrection2D\n",
    "from utils import MaxProjection, VarianceFilterTime, MidSlices, normalizeZeroOne, showImageNapari\n",
    "import glob\n",
    "import numpy as np\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "from bokeh.models import Range1d\n",
    "try:\n",
    "    from pathlib import Path\n",
    "    Path().expanduser()\n",
    "except (ImportError, AttributeError):\n",
    "        from pathlib2 import Path\n",
    "\n",
    "try:\n",
    "        import tempfile\n",
    "        tempfile.TemporaryDirectory\n",
    "except (ImportError, AttributeError):\n",
    "       from backports import tempfile\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.filters import roberts, sobel, scharr, prewitt, gaussian\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from skimage.morphology import watershed\n",
    "from skimage.feature import peak_local_max, canny\n",
    "\n",
    "from skimage.segmentation import find_boundaries,find_boundaries, relabel_sequential\n",
    "from scipy.ndimage.morphology import distance_transform_edt, binary_fill_holes, binary_dilation\n",
    "from skimage.exposure import rescale_intensity\n",
    "from skimage import data, io\n",
    "\n",
    "\n",
    "from skimage.morphology import remove_small_objects, binary_erosion\n",
    "\n",
    "#!pip install napari\n",
    "import napari\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now specify the source directory path, results directory path. Even if the results directory does not exist we can create one using Pathlib functions. The os function joins all the tif files found in the source directory. Axes keyword is used to specify the axis of the image we are interested to write in as a tiff file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourcedir = '/Users/aimachine/sample_images_python/'\n",
    "resultsdir = '/Users/aimachine/sample_images_python/Results/'\n",
    "Path(resultsdir).mkdir(exist_ok = True)\n",
    "Raw_path = os.path.join(sourcedir, '*tif')\n",
    "X = glob.glob(Raw_path)\n",
    "axes = 'ZYX'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the names of the tif files found in the directory and the shape of images. Shape is a keyword in Python used to indicate the dimensions along each axis, For example it could be 100 time points, 3 channels, and 500 by 400 XY dimensions. In such case the shape would be (100,3,500,400) (Be careful about XY axes, sometimes they may appear be YX instead of XY, so a rotated image of the original image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/aimachine/sample_images_python/190905_e2_MyoGFP_mTmG-python.tif (5, 31, 2, 1093, 1107) 5 0 1\n"
     ]
    }
   ],
   "source": [
    "All4Dimages = []\n",
    "All5Dimages = []\n",
    "for fname in X:\n",
    "\n",
    "    image = imread(fname)\n",
    "    if len(image.shape) == 4:\n",
    "        All4Dimages.append(image)\n",
    "    if len(image.shape) > 4:\n",
    "        All5Dimages.append(image)\n",
    "    \n",
    "    print(fname, image.shape, len(image.shape), len(All4Dimages), len(All5Dimages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Always a good idea to Normalize images before doing morphological operations that depend on the image intensity\n",
    "\n",
    "1) The percentile based normalization code is taken from csbdeep repo and added as a function in the utils directory which we imported in the first cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the image with TZCYX shape and choose a channel, do max projection along Z (axis = 1), making a time lapse image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 31, 2, 1093, 1107)\n",
      "(5, 2, 1093, 1107)\n",
      "(5, 1093, 1107)\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "\n",
    "channel = 1\n",
    "\n",
    "\n",
    "FiveDimage = All5Dimages[idx]\n",
    "print(FiveDimage.shape)\n",
    "\n",
    "#Select Central Z region to do the max projection\n",
    "\n",
    "FourDimage = MidSlices(FiveDimage, axis = 1, slices= 2)\n",
    "\n",
    "print(FourDimage.shape)\n",
    "ThreeDimage = FourDimage[:,channel,:]\n",
    "print(ThreeDimage.shape)\n",
    "TotalTimePoints = ThreeDimage.shape[0]  \n",
    "#Image shape now is TYX\n",
    "ThreeDimage = NormalizeFloat(ThreeDimage, 1, 99.8)\n",
    "for i in range(0,(ThreeDimage.shape[0])):\n",
    "        ThreeDimage[i,:,:] =  normalizeZeroOne(ThreeDimage[i,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreProcessing of images is always essential to getting a good segmentation.\n",
    "1) Do BackGround correction, apply a 'huge' sigma to create a dark image and then subtract this image from the original image, this is implemented in a function we define in the utils directory which is imported in the first block\n",
    "\n",
    "\n",
    "2) Do Median filtering on the resulting image with 'small' sigma to create a edge-preserved image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<napari.viewer.Viewer at 0x10f8d62e8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'%gui qt'\n",
    "showImageNapari(ThreeDimage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<napari.viewer.Viewer at 0x16af652e8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blur_radius = (20,20)\n",
    "boxsize = 105\n",
    "# Instead of 3D Kernel we can do slice by slice operation as well\n",
    "TwoDCorrectedThreeDimage = np.zeros([ThreeDimage.shape[0],ThreeDimage.shape[1], ThreeDimage.shape[2]]) \n",
    "TwoDMedianThreeDimage = np.zeros([ThreeDimage.shape[0],ThreeDimage.shape[1], ThreeDimage.shape[2]]) \n",
    "TwoDCannyThreeDimage = np.zeros([ThreeDimage.shape[0],ThreeDimage.shape[1], ThreeDimage.shape[2]]) \n",
    "TwoDBinaryThreeDimage = np.zeros([ThreeDimage.shape[0],ThreeDimage.shape[1], ThreeDimage.shape[2]]) \n",
    "median_filter_radius = (4,4)\n",
    "for j in range(0, ThreeDimage.shape[0]):\n",
    " \n",
    "    TwoDCorrectedThreeDimage[j,:] = BackGroundCorrection2D(ThreeDimage[j,:], blur_radius) \n",
    "    TwoDMedianThreeDimage[j,:] = MedianFilter(TwoDCorrectedThreeDimage[j,:], median_filter_radius)\n",
    "    TwoDCannyThreeDimage[j,:] = Canny(TwoDMedianThreeDimage[j,:], 1)\n",
    "    TwoDBinaryThreeDimage[j,:] = LocalThreshold2D(TwoDCannyThreeDimage[j,:], boxsize)\n",
    "\n",
    "showImageNapari(TwoDMedianThreeDimage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO DO Stopping for now "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the Preprocessed images as ImageJ compatiable tiff files\n",
    "save_tiff_imagej_compatible((resultsdir + \"Blur\" + '.tif') , BinaryThreeDimage, axes)\n",
    "save_tiff_imagej_compatible((resultsdir + \"2DBlur\" + '.tif') ,TwoDMedianThreeDimage, axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do Distance transform on 3D and 2D slice by slice blurred image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Binary image using Otsu threshold by first enhancing the edges using canny edge detection\n",
    "TotalTimePoints = BlurredThreeDimage.shape[0]\n",
    "ThreeDedge= np.zeros([BlurredThreeDimage.shape[0],BlurredThreeDimage.shape[1], BlurredThreeDimage.shape[2]])\n",
    "TwoDThreeDedge = np.zeros([BlurredThreeDimage.shape[0],BlurredThreeDimage.shape[1], BlurredThreeDimage.shape[2]])\n",
    "ThreeDbinary = np.zeros([BlurredThreeDimage.shape[0],BlurredThreeDimage.shape[1], BlurredThreeDimage.shape[2]]) \n",
    "TwoDThreeDbinary = np.zeros([BlurredThreeDimage.shape[0],BlurredThreeDimage.shape[1], BlurredThreeDimage.shape[2]]) \n",
    "ThreeDdistance = np.zeros([BlurredThreeDimage.shape[0],BlurredThreeDimage.shape[1], BlurredThreeDimage.shape[2]]) \n",
    "TwoDBlurThreeDdistance = np.zeros([BlurredThreeDimage.shape[0],BlurredThreeDimage.shape[1], BlurredThreeDimage.shape[2]]) \n",
    "\n",
    "\n",
    "for j in range(0, TotalTimePoints):\n",
    " ThreeDedge[j,:] = canny(BlurredThreeDimage[j,:], sigma = 0.1)\n",
    "\n",
    " ThreeDthresh = threshold_mean(ThreeDedge[j,:])\n",
    " ThreeDbinary[j,:] = ThreeDedge[j,:] > ThreeDthresh\n",
    " ThreeDbinary[j,:] = binary_dilation(ThreeDbinary[j,:])\n",
    " ThreeDbinary[j,:] = binary_fill_holes(ThreeDbinary[j,:]) \n",
    "\n",
    "\n",
    " TwoDThreeDedge[j,:] = canny(TwoDBlurredThreeDimage[j,:], sigma = 0.1)\n",
    "\n",
    " TwoDThreeDthresh = threshold_mean(TwoDThreeDedge[j,:])\n",
    " TwoDThreeDbinary[j,:] = TwoDThreeDedge[j,:] > TwoDThreeDthresh\n",
    " TwoDThreeDbinary[j,:] = binary_dilation(TwoDThreeDbinary[j,:])\n",
    " TwoDThreeDbinary[j,:] = binary_fill_holes(TwoDThreeDbinary[j,:])     \n",
    "    \n",
    "\n",
    " #Do the distance transform and compare the two Blurring methods\n",
    " ThreeDdistance[j,:] = ndi.distance_transform_edt(np.logical_not((ThreeDbinary[j,:].astype('uint8'))))\n",
    " TwoDBlurThreeDdistance[j,:] = ndi.distance_transform_edt(np.logical_not((TwoDThreeDbinary[j,:].astype('uint8'))))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Binaries\n",
    "save_tiff_imagej_compatible((resultsdir + \"Binary\" + '.tif') ,  ThreeDbinary, axes)\n",
    "save_tiff_imagej_compatible((resultsdir + \"2DBlurBinary\" + '.tif') ,TwoDThreeDbinary, axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 10\n",
    "plt.figure(figsize = (20,10))\n",
    "TotalTimePoints = ThreeDdistance.shape[0]\n",
    "for j in range(0, TotalTimePoints):\n",
    "        plt.subplot(TotalTimePoints/cols + 1 , cols, j + 1 )      \n",
    "        plt.imshow((ThreeDdistance[j,:]) , cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 10\n",
    "plt.figure(figsize = (20,10))\n",
    "TotalTimePoints = TwoDBlurThreeDdistance.shape[0]\n",
    "for j in range(0, TotalTimePoints):\n",
    "        plt.subplot(TotalTimePoints/cols + 1 , cols, j + 1 )      \n",
    "        plt.imshow((TwoDBlurThreeDdistance[j,:]), cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Save the slice by slice distance transformed image in results directory\n",
    "save_tiff_imagej_compatible((resultsdir + \"DistTransform\" + '.tif') ,  ThreeDdistance, axes)\n",
    "save_tiff_imagej_compatible((resultsdir + \"2DBlurDistTransform\" + '.tif') ,TwoDBlurThreeDdistance, axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying 3D watershed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = WatershedImage(ThreeDdistance, 3,3,3 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 10\n",
    "plt.figure(figsize = (20,10))\n",
    "TotalTimePoints = labels.shape[0]\n",
    "for j in range(0, TotalTimePoints):\n",
    "        plt.subplot(TotalTimePoints/cols + 1 , cols, j + 1 )      \n",
    "        plt.imshow(labels[j,:], cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_second = WatershedImageMarker(TwoDBlurThreeDdistance,TwoDThreeDbinary, 3,3,3 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 10\n",
    "plt.figure(figsize = (20,10))\n",
    "TotalTimePoints = labels_second.shape[0]\n",
    "for j in range(0, TotalTimePoints):\n",
    "        plt.subplot(TotalTimePoints/cols + 1 , cols, j + 1 )      \n",
    "        plt.imshow(labels_second[j,:], cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the slice by slice distance transformed image in results directory\n",
    "save_tiff_imagej_compatible((resultsdir + \"Watershed\" + '.tif') ,  labels, axes)\n",
    "save_tiff_imagej_compatible((resultsdir + \"2DBlurWatershed\" + '.tif') ,labels_second, axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying 2D watershed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = np.zeros([BlurredThreeDimage.shape[0],BlurredThreeDimage.shape[1], BlurredThreeDimage.shape[2]])\n",
    "for j in range(0, TotalTimePoints):\n",
    " labels[j,:] = WatershedImage(ThreeDdistance[j,:], 3,3 )  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 10\n",
    "plt.figure(figsize = (20,10))\n",
    "TotalTimePoints = labels.shape[0]\n",
    "for j in range(0, TotalTimePoints):\n",
    "        plt.subplot(TotalTimePoints/cols + 1 , cols, j + 1 )      \n",
    "        plt.imshow(labels[j,:], cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels_second = np.zeros([BlurredThreeDimage.shape[0],BlurredThreeDimage.shape[1], BlurredThreeDimage.shape[2]])\n",
    "for j in range(0, TotalTimePoints):\n",
    " labels_second[j,:] = WatershedImage(TwoDBlurThreeDdistance[j,:], 3,3 )  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_tiff_imagej_compatible((resultsdir + \"TwoDimensionalWatershed\" + '.tif') ,  labels, axes)\n",
    "save_tiff_imagej_compatible((resultsdir + \"2DBlurTwoDimensionalWatershed\" + '.tif') ,  labels_second, axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflowEnv36",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
