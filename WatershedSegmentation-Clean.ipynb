{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Watershedding on a TYX shape image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages to open and view tiffile, other python packages to deal with loading images from a certain directory. For writting results we need to create another directory, this is done by pathlib. Local function definations are included in the utils.py file which is imported along with other python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tifffile import imread\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "from utils import NormalizeFloat, save_tiff_imagej_compatible,WatershedImage\n",
    "from utils import MedianFilter, LocalThreshold3D, LocalThreshold2D,OtsuThreshold2D, Canny3D, Canny,BackGroundCorrection3D,BackGroundCorrection2D\n",
    "from utils import MaxProjection, VarianceFilterTime, MidSlices, normalizeZeroOne, showImageNapari,Embryo_plot, SelectSlice, BinaryDilation\n",
    "import glob\n",
    "import numpy as np\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "from bokeh.models import Range1d\n",
    "try:\n",
    "    from pathlib import Path\n",
    "    Path().expanduser()\n",
    "except (ImportError, AttributeError):\n",
    "        from pathlib2 import Path\n",
    "\n",
    "try:\n",
    "        import tempfile\n",
    "        tempfile.TemporaryDirectory\n",
    "except (ImportError, AttributeError):\n",
    "       from backports import tempfile\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.filters import roberts, sobel, scharr, prewitt, gaussian\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from skimage.morphology import watershed\n",
    "from skimage.feature import peak_local_max, canny\n",
    "\n",
    "from skimage.segmentation import find_boundaries,find_boundaries, relabel_sequential\n",
    "from scipy.ndimage.morphology import distance_transform_edt, binary_fill_holes, binary_dilation\n",
    "from skimage.exposure import rescale_intensity\n",
    "from skimage import data, io\n",
    "\n",
    "\n",
    "from skimage.morphology import remove_small_objects, binary_erosion\n",
    "\n",
    "#!pip install napari\n",
    "import napari\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now specify the source directory path, results directory path. Even if the results directory does not exist we can create one using Pathlib functions. The os function joins all the tif files found in the source directory. Axes keyword is used to specify the axis of the image we are interested to write in as a tiff file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourcedir = '/Users/aimachine/Documents/OzEmbryo/'\n",
    "resultsdir = '/Users/aimachine/Documents/OzEmbryo/Results/'\n",
    "Path(resultsdir).mkdir(exist_ok = True)\n",
    "Raw_path = os.path.join(sourcedir, '*tif')\n",
    "X = glob.glob(Raw_path)\n",
    "axes = 'TYX'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the names of the tif files found in the directory and the shape of images. Shape is a keyword in Python used to indicate the dimensions along each axis, For example it could be 100 time points, 3 channels, and 500 by 400 XY dimensions. In such case the shape would be (100,3,500,400) (Be careful about XY axes, sometimes they may appear be YX instead of XY, so a rotated image of the original image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/aimachine/Documents/OzEmbryo/C2-ReCompaction_e2_2.tif (121, 792, 901) 3 1 0 0\n",
      "/Users/aimachine/Documents/OzEmbryo/C2-CaFree_z1.tif (121, 941, 941) 3 2 0 0\n"
     ]
    }
   ],
   "source": [
    "All4Dimages = []\n",
    "All5Dimages = []\n",
    "All3Dimages = []\n",
    "for fname in X:\n",
    "\n",
    "    image = imread(fname)\n",
    "    if len(image.shape) == 3:\n",
    "        All3Dimages.append(image)\n",
    "    if len(image.shape) == 4:\n",
    "        All4Dimages.append(image)\n",
    "    if len(image.shape) > 4:\n",
    "        All5Dimages.append(image)\n",
    "    \n",
    "    print(fname, image.shape, len(image.shape), len(All3Dimages), len(All4Dimages), len(All5Dimages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Always a good idea to Normalize images before doing morphological operations that depend on the image intensity\n",
    "\n",
    "1) The percentile based normalization code is taken from csbdeep repo and added as a function in the utils directory which we imported in the first cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the image with TZCYX shape and choose a channel, do max projection along Z (axis = 1), making a time lapse image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-016fe52b15a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mFiveDimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAll5Dimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFiveDimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "\n",
    "channel = 1\n",
    "\n",
    "if len(All5Dimages) > 0:\n",
    " FiveDimage = All5Dimages[idx]\n",
    " print(FiveDimage.shape)\n",
    "\n",
    " #Select Central Z region to do the max projection\n",
    "\n",
    " FourDimage = SelectSlice(FiveDimage, axis = 1, slicenumber = 23)\n",
    "\n",
    " print(FourDimage.shape)\n",
    " ThreeDimage = FourDimage[:,0,channel,:]\n",
    " print(ThreeDimage.shape)\n",
    " TotalTimePoints = ThreeDimage.shape[0]  \n",
    " #Image shape now is TYX\n",
    " ThreeDimage = NormalizeFloat(ThreeDimage, 1, 99.8)\n",
    " for i in range(0,(ThreeDimage.shape[0])):\n",
    "        ThreeDimage[i,:,:] =  normalizeZeroOne(ThreeDimage[i,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(121, 792, 901)\n"
     ]
    }
   ],
   "source": [
    "#If you only have 3D image else skip this block\n",
    "\n",
    "idx = 0\n",
    "if len(All3Dimages) > 0:\n",
    " ThreeDimage = All3Dimages[idx]\n",
    " TotalTimePoints = ThreeDimage.shape[0] \n",
    " ThreeDimage = NormalizeFloat(ThreeDimage, 1, 99.8)\n",
    " for i in range(0,(ThreeDimage.shape[0])):\n",
    "        ThreeDimage[i,:,:] =  normalizeZeroOne(ThreeDimage[i,:,:])\n",
    "        \n",
    " print(ThreeDimage.shape)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreProcessing of images is always essential to getting a good segmentation.\n",
    "1) Do BackGround correction, apply a 'huge' sigma to create a dark image and then subtract this image from the original image, this is implemented in a function we define in the utils directory which is imported in the first block\n",
    "\n",
    "\n",
    "2) Do Median filtering on the resulting image with 'small' sigma to create a edge-preserved image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur_radius = (25,25)\n",
    "\n",
    "Size_remove = 1000\n",
    "TwoDCorrectedThreeDimage = np.zeros([ThreeDimage.shape[0],ThreeDimage.shape[1], ThreeDimage.shape[2]]) \n",
    "TwoDMedianThreeDimage = np.zeros([ThreeDimage.shape[0],ThreeDimage.shape[1], ThreeDimage.shape[2]]) \n",
    "TwoDBinaryThreeDimage = np.zeros([ThreeDimage.shape[0],ThreeDimage.shape[1], ThreeDimage.shape[2]]) \n",
    "TwoDDilatedThreeDimage = np.zeros([ThreeDimage.shape[0],ThreeDimage.shape[1], ThreeDimage.shape[2]]) \n",
    "CannyThreeDimage = np.zeros([ThreeDimage.shape[0],ThreeDimage.shape[1], ThreeDimage.shape[2]]) \n",
    "median_filter_radius = (8,8)\n",
    "for j in range(0, ThreeDimage.shape[0]):\n",
    "    \n",
    "    TwoDCorrectedThreeDimage[j,:] = BackGroundCorrection2D(ThreeDimage[j,:], blur_radius) \n",
    "    TwoDMedianThreeDimage[j,:] = MedianFilter(TwoDCorrectedThreeDimage[j,:], median_filter_radius)\n",
    "    \n",
    "    TwoDBinaryThreeDimage[j,:] = OtsuThreshold2D(TwoDMedianThreeDimage[j,:], size = Size_remove)\n",
    "    CannyThreeDimage[j,:] = Canny(TwoDBinaryThreeDimage[j,:], sigma = 3)\n",
    "    TwoDDilatedThreeDimage[j,:] = BinaryDilation(TwoDBinaryThreeDimage[j,:], iterations = 20)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#close the viewer to procees next\n",
    "\n",
    "showImageNapari(ThreeDimage,TwoDDilatedThreeDimage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aimachine/BioPython/utils.py:371: UserWarning: Converting data type from 'float64' to ImageJ-compatible 'float32'.\n",
      "  warnings.warn(\"Converting data type from '%s' to ImageJ-compatible '%s'.\" % (t, np.dtype(t_new)))\n",
      "/Users/aimachine/BioPython/utils.py:242: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  x = x[slices]\n"
     ]
    }
   ],
   "source": [
    "#Save the Binaryimages as ImageJ compatiable tiff files\n",
    "save_tiff_imagej_compatible((resultsdir + \"2DBlur\" + '.tif') ,TwoDDilatedThreeDimage, axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do Distance transform on 2D slice by slice blurred image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "TotalTimePoints = ThreeDimage.shape[0] \n",
    "\n",
    "TwoDBlurThreeDdistance = np.zeros([TwoDDilatedThreeDimage.shape[0],TwoDDilatedThreeDimage.shape[1], TwoDDilatedThreeDimage.shape[2]]) \n",
    "\n",
    "\n",
    "for j in range(0, TotalTimePoints):\n",
    " \n",
    " TwoDBlurThreeDdistance[j,:] = ndi.distance_transform_edt(np.logical_not((CannyThreeDimage[j,:])))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "showImageNapari(ThreeDimage,TwoDBlurThreeDdistance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aimachine/BioPython/utils.py:371: UserWarning: Converting data type from 'float64' to ImageJ-compatible 'float32'.\n",
      "  warnings.warn(\"Converting data type from '%s' to ImageJ-compatible '%s'.\" % (t, np.dtype(t_new)))\n",
      "/Users/aimachine/BioPython/utils.py:242: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  x = x[slices]\n"
     ]
    }
   ],
   "source": [
    "#Save the slice by slice distance transformed image in results directory\n",
    "save_tiff_imagej_compatible((resultsdir + \"2DBlurDistTransform\" + '.tif') ,TwoDBlurThreeDdistance, axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D watershed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Time = []\n",
    "Embryos = []\n",
    "Seed_dist = 50\n",
    "labels = np.zeros([TwoDBlurThreeDdistance.shape[0],TwoDBlurThreeDdistance.shape[1], TwoDBlurThreeDdistance.shape[2]])\n",
    "for j in range(0, TotalTimePoints):\n",
    " labels[j,:] = WatershedImage(TwoDBlurThreeDdistance[j,:], 5,5, min_distance = Seed_dist ) \n",
    " Time.append(j)\n",
    " Embryos.append(np.amax(labels[j,:]) - np.amin(labels[j,:]) ) \n",
    "\n",
    "Embryo_plot(Time, Embryos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "showImageNapari(ThreeDimage,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aimachine/BioPython/utils.py:371: UserWarning: Converting data type from 'float64' to ImageJ-compatible 'float32'.\n",
      "  warnings.warn(\"Converting data type from '%s' to ImageJ-compatible '%s'.\" % (t, np.dtype(t_new)))\n",
      "/Users/aimachine/BioPython/utils.py:242: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  x = x[slices]\n"
     ]
    }
   ],
   "source": [
    "save_tiff_imagej_compatible((resultsdir + \"TwoDimensionalWatershed\" + '.tif') ,  labels, axes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflowEnv36",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
